{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages**"
      ],
      "metadata": {
        "id": "gMH_Xlg-Evpa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8_SXo-4PDrmz"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading data set**"
      ],
      "metadata": {
        "id": "TE20WVcYE35X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook we will use [Shakespeare Sonnets Dataset,](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154) which contains more than 2000 lines of text extracted from Shakespeare's sonnets.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "C6zjU1UoERDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ],
      "metadata": {
        "id": "76-Z64lIEFUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/NLP projects/Text generation/sonnets.txt') as f:\n",
        "  data = f.read()\n",
        "\n",
        "corpus = data.lower().split('\\n')\n",
        "\n",
        "print(f'There are {len(corpus)} line of sonnets\\n')\n",
        "print(f'The first 6 lines looks like :')\n",
        "for i in range(6) :\n",
        "  print(f'\\t{corpus[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHWc2Cb7FN0b",
        "outputId": "78738152-9ff2-457f-b501-caacb9d942bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 line of sonnets\n",
            "\n",
            "The first 6 lines looks like :\n",
            "\tfrom fairest creatures we desire increase,\n",
            "\tthat thereby beauty's rose might never die,\n",
            "\tbut as the riper should by time decease,\n",
            "\this tender heir might bear his memory:\n",
            "\tbut thou, contracted to thine own bright eyes,\n",
            "\tfeed'st thy light'st flame with self-substantial fuel,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "fYYViJCQGmEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# NOTE : +1 is the 'OOV' word\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "57laG1lzGUyS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notation** \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "before using texts_to_sequences (converting corpus into sequences) texts_to_sequences expects a list as input and list as output while the input is a string\n",
        "* so as solution we will pass the string as list for input \n",
        "* and take the first element of the output \n",
        "* To understand more look for the next example"
      ],
      "metadata": {
        "id": "jXlt2oloHxxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wPOlKOupHHc1",
        "outputId": "f093547b-1957-4235-96d8-4a3adb955152"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBOq2OQ8JCGK",
        "outputId": "e31bad9b-da21-4971-d265-26127daad938"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ot = tokenizer.texts_to_sequences([corpus[0]])\n",
        "ot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeb0XidOJHXa",
        "outputId": "b71c93a5-e527-4d81-e8b3-14a540133361"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = ot[0]\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CngU5oOtJM4U",
        "outputId": "d295c9e1-eb08-4467-8784-05c6430c0fd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **N-Grams**"
      ],
      "metadata": {
        "id": "jYXa4qNVJ8_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams(corpus, tokenizer) :\n",
        "  \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "    \n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "  \"\"\"\n",
        "\n",
        "  input_seq = []\n",
        "\n",
        "  for line in corpus : \n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    for i in range(1, len(token_list)) :\n",
        "      n_gram_seq = token_list[:i+1]\n",
        "      input_seq.append(n_gram_seq)\n",
        "\n",
        "  return input_seq "
      ],
      "metadata": {
        "id": "Z76at-MRJVTB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_example_sequence = n_grams([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlYEIR2sM32p",
        "outputId": "b4aaa204-e3cd-4bb7-9548-acc1326b234e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_3_examples_sequence = n_grams(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AkQYo7rM_qi",
        "outputId": "35310bb5-1291-4064-954e-ad8a87d58e82"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying for the whole corpus**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P-oz9Z7rNgRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = n_grams(corpus, tokenizer)\n",
        "\n",
        "max_input_seq_len = max([len(i) for i in input_seq])\n",
        "\n",
        "print(f'Max length of n-grams = {max_input_seq_len}')\n",
        "print(f'len on n-grams = {len(input_seq)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9A4zRM4NceL",
        "outputId": "c72822ed-e664-4a3b-9e88-3f16f2078e8a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max lne of n-grams = 11\n",
            "len on n-grams = 15462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Padding**"
      ],
      "metadata": {
        "id": "S_ATNSsBOvbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_seq(input_seq, max_len) :\n",
        "  \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "    \n",
        "    Args:\n",
        "        input_seq (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "  \"\"\"\n",
        "\n",
        "  max_seq_len = max([len(x) for x in input_seq])\n",
        "  padded_seq = np.array(pad_sequences(input_seq, maxlen = max_seq_len, padding='pre'))\n",
        "\n",
        "  return padded_seq\n"
      ],
      "metadata": {
        "id": "YwseHbSrOQoZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_padded_seq = pad_seq(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Ix8LalRVeR",
        "outputId": "b3652ccd-d529-4d5e-dbd6-0a450699484a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,  34, 417, 877, 166],\n",
              "       [  0,  34, 417, 877, 166, 213],\n",
              "       [ 34, 417, 877, 166, 213, 517]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the whole corpus\n",
        "padded_input_seq = pad_seq(input_seq, max_input_seq_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF5USDZkRYa-",
        "outputId": "1f3ec9dd-65b6-43da-ade8-88b090f63eb1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting data**"
      ],
      "metadata": {
        "id": "VR6YNSRGR2K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features_and_labels(input_seq, total_words) :\n",
        "  \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "    \n",
        "    Args:\n",
        "        input_seq (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "    \n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "  \"\"\"\n",
        "\n",
        "  features = input_seq[:, :-1]\n",
        "  labels = input_seq[:,-1]\n",
        "  one_hot_labels  = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "  return features, one_hot_labels "
      ],
      "metadata": {
        "id": "w41vsp6WRuGK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H66ecX-jS9E1",
        "outputId": "7fe03071-814e-460c-fa8d-064e85be3bd2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(padded_input_seq, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP-roMriTJER",
        "outputId": "f70f524e-6096-4334-e1cc-dc6313214aa7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "EUiaos9GUCUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(total_words, max_input_seq_len):\n",
        "  model= tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding(total_words, 100, input_length = max_input_seq_len -1),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "      tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "mtQgkwsSTRhX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(total_words, max_input_seq_len)\n",
        "\n",
        "history = model.fit(features, labels, epochs= 50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHJ7h-W9VhJY",
        "outputId": "05bbd9c1-70de-4fb5-d59c-2a8a4e947fc6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "484/484 [==============================] - 41s 75ms/step - loss: 6.8893 - accuracy: 0.0232\n",
            "Epoch 2/50\n",
            "484/484 [==============================] - 34s 70ms/step - loss: 6.4261 - accuracy: 0.0321\n",
            "Epoch 3/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 6.1851 - accuracy: 0.0413\n",
            "Epoch 4/50\n",
            "484/484 [==============================] - 35s 73ms/step - loss: 5.9176 - accuracy: 0.0515\n",
            "Epoch 5/50\n",
            "484/484 [==============================] - 34s 70ms/step - loss: 5.5999 - accuracy: 0.0644\n",
            "Epoch 6/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 5.2256 - accuracy: 0.0770\n",
            "Epoch 7/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 4.8162 - accuracy: 0.0974\n",
            "Epoch 8/50\n",
            "484/484 [==============================] - 35s 72ms/step - loss: 4.3845 - accuracy: 0.1348\n",
            "Epoch 9/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 3.9524 - accuracy: 0.1925\n",
            "Epoch 10/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 3.5400 - accuracy: 0.2581\n",
            "Epoch 11/50\n",
            "484/484 [==============================] - 35s 72ms/step - loss: 3.1759 - accuracy: 0.3324\n",
            "Epoch 12/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 2.8460 - accuracy: 0.3946\n",
            "Epoch 13/50\n",
            "484/484 [==============================] - 37s 75ms/step - loss: 2.5562 - accuracy: 0.4549\n",
            "Epoch 14/50\n",
            "484/484 [==============================] - 35s 72ms/step - loss: 2.3046 - accuracy: 0.5069\n",
            "Epoch 15/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 2.0878 - accuracy: 0.5528\n",
            "Epoch 16/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 1.8922 - accuracy: 0.5989\n",
            "Epoch 17/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 1.7152 - accuracy: 0.6414\n",
            "Epoch 18/50\n",
            "484/484 [==============================] - 35s 73ms/step - loss: 1.5611 - accuracy: 0.6740\n",
            "Epoch 19/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 1.4200 - accuracy: 0.7047\n",
            "Epoch 20/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 1.2954 - accuracy: 0.7337\n",
            "Epoch 21/50\n",
            "484/484 [==============================] - 35s 71ms/step - loss: 1.1936 - accuracy: 0.7546\n",
            "Epoch 22/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 1.1026 - accuracy: 0.7717\n",
            "Epoch 23/50\n",
            "484/484 [==============================] - 35s 73ms/step - loss: 1.0218 - accuracy: 0.7915\n",
            "Epoch 24/50\n",
            "484/484 [==============================] - 34s 71ms/step - loss: 0.9493 - accuracy: 0.8041\n",
            "Epoch 25/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 0.8861 - accuracy: 0.8153\n",
            "Epoch 26/50\n",
            "484/484 [==============================] - 35s 72ms/step - loss: 0.8408 - accuracy: 0.8214\n",
            "Epoch 27/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 0.7994 - accuracy: 0.8274\n",
            "Epoch 28/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 0.7671 - accuracy: 0.8307\n",
            "Epoch 29/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 0.7363 - accuracy: 0.8366\n",
            "Epoch 30/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 0.7050 - accuracy: 0.8388\n",
            "Epoch 31/50\n",
            "484/484 [==============================] - 37s 77ms/step - loss: 0.6883 - accuracy: 0.8429\n",
            "Epoch 32/50\n",
            "484/484 [==============================] - 37s 77ms/step - loss: 0.6738 - accuracy: 0.8430\n",
            "Epoch 33/50\n",
            "484/484 [==============================] - 37s 77ms/step - loss: 0.6615 - accuracy: 0.8456\n",
            "Epoch 34/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 0.6515 - accuracy: 0.8433\n",
            "Epoch 35/50\n",
            "484/484 [==============================] - 37s 76ms/step - loss: 0.6366 - accuracy: 0.8458\n",
            "Epoch 36/50\n",
            "484/484 [==============================] - 38s 78ms/step - loss: 0.6230 - accuracy: 0.8472\n",
            "Epoch 37/50\n",
            "484/484 [==============================] - 37s 77ms/step - loss: 0.6132 - accuracy: 0.8480\n",
            "Epoch 38/50\n",
            "484/484 [==============================] - 36s 75ms/step - loss: 0.6081 - accuracy: 0.8478\n",
            "Epoch 39/50\n",
            "484/484 [==============================] - 36s 74ms/step - loss: 0.6081 - accuracy: 0.8470\n",
            "Epoch 40/50\n",
            "484/484 [==============================] - 38s 78ms/step - loss: 0.6035 - accuracy: 0.8487\n",
            "Epoch 41/50\n",
            "484/484 [==============================] - 39s 80ms/step - loss: 0.5924 - accuracy: 0.8495\n",
            "Epoch 42/50\n",
            "484/484 [==============================] - 39s 80ms/step - loss: 0.5903 - accuracy: 0.8473\n",
            "Epoch 43/50\n",
            "484/484 [==============================] - 40s 82ms/step - loss: 0.5863 - accuracy: 0.8481\n",
            "Epoch 44/50\n",
            "484/484 [==============================] - 39s 81ms/step - loss: 0.5835 - accuracy: 0.8485\n",
            "Epoch 45/50\n",
            "484/484 [==============================] - 39s 81ms/step - loss: 0.5806 - accuracy: 0.8489\n",
            "Epoch 46/50\n",
            "484/484 [==============================] - 39s 80ms/step - loss: 0.5735 - accuracy: 0.8492\n",
            "Epoch 47/50\n",
            "484/484 [==============================] - 38s 78ms/step - loss: 0.5721 - accuracy: 0.8489\n",
            "Epoch 48/50\n",
            "484/484 [==============================] - 38s 78ms/step - loss: 0.5707 - accuracy: 0.8481\n",
            "Epoch 49/50\n",
            "484/484 [==============================] - 39s 80ms/step - loss: 0.5678 - accuracy: 0.8487\n",
            "Epoch 50/50\n",
            "484/484 [==============================] - 38s 80ms/step - loss: 0.5658 - accuracy: 0.8486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Next_words.h5')"
      ],
      "metadata": {
        "id": "dSo75bB9aA8Y"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "-EEKMDNGV-ou",
        "outputId": "094ce371-47ef-47e7-bc58-9dc5ff892d55"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **History as pickle**"
      ],
      "metadata": {
        "id": "bOby1WQJZmHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BXlRHZinZbHn",
        "outputId": "6a40b5fc-b424-4611-fd89-11ca3fd3f1fd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8dfa86e9-c5ca-4f5d-b23e-dd04313bf692\", \"history.pkl\", 942)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model in action**"
      ],
      "metadata": {
        "id": "nhu2e8xvZh9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_input_seq_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXrgtdWXZhQ-",
        "outputId": "1c27809e-a09a-45fc-eda8-3b13a77ac070"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope and loss of thine eyes thee her all too near me 'will ' have end it told i joy have it no old glad is best ' that that mine eye not lies lies near 'will so free ' speak the ever looks now may say you so poet is not so show ' ' with thee with me can mine eye eye with thy part ' with my tongue one part may know thy place thy 'will ' blind lie with mine own bright thy part ever thee i think thee thence her chest live wide treasure new long\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOx1sPKcdj5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}